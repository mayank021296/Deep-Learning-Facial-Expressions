# DL_Facial_Emotion_Recognition_Using_CNN

## ğŸ“Œ Project Overview

Facial Expression Recognition is a deep learningâ€“based computer vision project that aims to automatically identify human emotions from facial images. This project uses a **Convolutional Neural Network (CNN)** to classify facial expressions into multiple emotion categories such as angry, happy, sad, fear, surprise, disgust, and neutral.

The model is trained on a labeled dataset of facial images and learns important facial features using convolutional layers.

---

## ğŸ¯ Objectives

* To understand the working of Convolutional Neural Networks
* To preprocess image data for deep learning models
* To build and train a CNN model for emotion classification
* To evaluate model performance on test data
* To gain hands-on experience with TensorFlow and Keras

---

## ğŸ§  Emotions Classified

The model classifies facial expressions into the following categories:

* Angry
* Disgust
* Fear
* Happy
* Sad
* Surprise
* Neutral

---

## ğŸ› ï¸ Technologies & Libraries Used

* **Python**
* **TensorFlow / Keras** â€“ Deep learning framework
* **OpenCV (cv2)** â€“ Image processing
* **NumPy** â€“ Numerical operations
* **Matplotlib** â€“ Visualization (if used)
* **Kaggle API** â€“ Dataset download

---

## ğŸ“‚ Dataset

The dataset used for this project is obtained from **Kaggle**. It contains grayscale facial images categorized into different emotion folders.

### Dataset Features:

* Grayscale images
* Image size resized to 48x48 pixels
* Organized into training and testing sets

---

## âš™ï¸ Project Workflow

1. Import required libraries
2. Download dataset using Kaggle API
3. Extract and explore dataset
4. Preprocess images (grayscale, resize, normalize)
5. Encode emotion labels
6. Build CNN model architecture
7. Compile the model
8. Train the model
9. Evaluate model performance
10. Save the trained model

---

## ğŸ—ï¸ CNN Architecture

* Convolutional Layers with ReLU activation
* Max Pooling layers
* Dropout layers to prevent overfitting
* Fully connected Dense layers
* Softmax output layer for multi-class classification

---

## ğŸ“Š Model Compilation

* **Optimizer:** Adam
* **Loss Function:** Categorical Crossentropy
* **Evaluation Metric:** Accuracy

---

## ğŸ’¾ Model Saving

The trained model is saved in `.h5` format so it can be reused without retraining.

---

## ğŸ“ˆ Results

The CNN model successfully learns facial features and classifies emotions with reasonable accuracy on the test dataset. Performance can be further improved using data augmentation and transfer learning.

---

## ğŸš€ Future Improvements

* Apply data augmentation techniques
* Use transfer learning models such as VGG16 or ResNet
* Implement real-time emotion detection using webcam
* Improve accuracy using a larger dataset

---

## ğŸ“Œ Applications

* Emotion-aware systems
* Humanâ€“computer interaction
* Mental health monitoring
* Online education platforms
* Smart surveillance systems

---

## ğŸ“œ Conclusion

This project demonstrates the effectiveness of Convolutional Neural Networks in facial expression recognition tasks. It provides practical exposure to deep learning, image processing, and model evaluation.

---

## â­ Acknowledgment

Dataset provided by Kaggle. This project is developed as part of an academic submission.

---

## ğŸ“ How to Run the Project

1. Clone the repository
2. Install required libraries
3. Set Kaggle API token
4. Run the Jupyter Notebook step by step

---

## ğŸ“¬ Contact

For any queries, feel free to reach out via GitHub.

---

â­ If you find this project useful, please consider giving it a star!
